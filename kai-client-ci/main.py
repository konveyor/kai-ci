import json
import shutil
import time
import os

import pandas as pd

from files import zip_folder, clone_repository, copy_file
from kai_handler import setup_and_run_demo, download_kai_files
from logger import get_logger

logger = get_logger(__name__)


# TODO (@abrugaro): Move utility functions to a different module
def to_camel_case(original_str):
    components = original_str.split(' ')
    return components[0].lower() + ''.join(x.title() for x in components[1:])


# TODO (@abrugaro) The kai_eval_report.csv file should be generated by the kai-evaluator and placed automatically in the data folder, then remove from output folder
def kai_eval_report_to_json():
    df = pd.read_csv('output/kai_eval_report.csv')
    df.columns = [to_camel_case(col) for col in df.columns]
    json_data = json.loads(df.to_json(orient='records'))
    total_incidents = len(json_data)
    average_effectiveness = round(sum(item['effectiveness'] for item in json_data) / total_incidents, 1)
    average_specificity = round(sum(item['specificity'] for item in json_data) / total_incidents, 1)
    average_reasoning = round(sum(item['reasoning'] for item in json_data) / total_incidents, 1)
    average_competency = round(sum(item['competency'] for item in json_data) / total_incidents, 1)
    average_score = round(sum(item['averageScore'] for item in json_data) / total_incidents, 1)

    return {
        'averageEffectiveness': average_effectiveness,
        'averageSpecificity': average_specificity,
        'averageReasoning': average_reasoning,
        'averageCompetency': average_competency,
        'averageScore': average_score,
        'data': json_data
    }


def append_to_json_array(file_path, new_data):
    with open(file_path, 'r', encoding='utf-8') as file:
        data = json.load(file)

    data.append(new_data)

    with open(file_path, 'w', encoding='utf-8') as file:
        json.dump(data, file, indent=4)


if __name__ == '__main__':

    if os.path.exists('data'):
        shutil.rmtree('data')
    os.makedirs('data')

    if os.path.exists('kai_files'):
        shutil.rmtree('kai_files')
    os.makedirs('kai_files')

    start = time.time()
    download_kai_files()

    # TODO (@abrugaro) These files are currently extracted from a Docker container so they are placed here as fixtures to allow the script to run in Windows.
    # Once these files are provided as part of a release of https://github.com/konveyor/java-analyzer-bundle they can be fetched as well
    files_to_move = ['jdtls', 'bundle.jar', 'maven.default.index']

    for file_name in files_to_move:
        source_path = os.path.join('./fixtures', file_name)
        target_path = os.path.join('./kai_files/kai/example/analysis', file_name)
        copy_file(source_path, target_path)

    copy_file('./fixtures/config.toml', './kai_files/kai/example/')
    clone_repository('rulesets', 'https://github.com/konveyor/rulesets.git', 'main')
    os.rename('data/rulesets/default/generated/', 'kai_files/kai/example/analysis/rulesets')

    clone_repository('coolstore', 'https://github.com/konveyor-ecosystem/coolstore', 'main')
    os.rename('data/coolstore', 'kai_files/kai/example/coolstore')

    setup_and_run_demo()

    # json_report = {
    #   'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    #   'kaiEvalData': kai_eval_report_to_json()
    # }
    # append_to_json_array('./output/report.json', json_report)

    # zip_path = zip_folder(os.path.join('data', f'{test_app_name}_{test_original_branch}'),
    #                          datetime.now().strftime('%Y-%m-%d--%H-%M'))
    # report_data_url = upload(zip_path)
    # logger.info(f'Report data uploaded to {report_data_url}')
    logger.info(f'Execution took {time.time() - start} seconds')
